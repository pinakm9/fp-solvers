{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1e98d09-b103-4054-9dfb-ef900e13c841",
   "metadata": {},
   "source": [
    "**Instructions for running this notebook on Colab**\n",
    "1. Run the cell below to download code from GitHub and install correct version of Python modules\n",
    "2. Restart session so that Colab can use the newly installed modules rather than their previously installed versions\n",
    "3. Run all cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46356898",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "46356898",
    "outputId": "cde07897-d928-4293-dd1e-1f1ddbae0be7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'fp-solvers'...\n",
      "remote: Enumerating objects: 15236, done.\u001b[K\n",
      "remote: Counting objects: 100% (606/606), done.\u001b[K\n",
      "remote: Compressing objects: 100% (337/337), done.\u001b[K\n",
      "remote: Total 15236 (delta 262), reused 596 (delta 258), pack-reused 14630\u001b[K\n",
      "Receiving objects: 100% (15236/15236), 849.97 MiB | 16.97 MiB/s, done.\n",
      "Resolving deltas: 100% (7417/7417), done.\n",
      "Updating files: 100% (14754/14754), done.\n",
      "/\n"
     ]
    }
   ],
   "source": [
    "# run this cell to download data and necessary modules\n",
    "import os, shutil\n",
    "repo = 'fp-solvers'\n",
    "if os.path.isdir(repo):\n",
    "  shutil.rmtree(repo)\n",
    "!git clone https://github.com/pinakm9/fp-solvers.git\n",
    "!pip install -r fp-solvers/requirements.txt 2> /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302e615d-a490-4d58-a615-c09298723ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add modules folder to Python's search path\n",
    "import os, sys\n",
    "from pathlib import Path\n",
    "script_dir = Path(os.path.dirname(os.path.abspath('')))\n",
    "module_dir = str(script_dir)\n",
    "sys.path.insert(0, repo + '/modules')\n",
    "print(module_dir)\n",
    "\n",
    "# import the rest of the modules\n",
    "%matplotlib nbagg\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import arch\n",
    "import pandas as pd\n",
    "import tensorflow_probability as tfp\n",
    "import time\n",
    "import sim\n",
    "import utility as ut\n",
    "import math\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.animation as animation\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "tfd = tfp.distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4be9da57",
   "metadata": {
    "id": "4be9da57"
   },
   "outputs": [],
   "source": [
    "# set up computation parameters\n",
    "dim = 3\n",
    "n_particles = int(1e7)\n",
    "n_subdivs = 100\n",
    "save_folder = '{}/one-step-filter/L63-pf'.format(repo)\n",
    "n_steps = 3\n",
    "n_repeats = 200\n",
    "dt = 0.01\n",
    "alpha, beta, rho = 10., 8./3., 28.\n",
    "t = dt * n_steps\n",
    "DTYPE = 'float32'\n",
    "seed = 42\n",
    "np.random.seed(seed=seed)\n",
    "tf.random.set_seed(seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f8afbd",
   "metadata": {
    "id": "01f8afbd"
   },
   "source": [
    "#### Define $\\mu, \\sigma, p_0, \\sigma_h$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45541914",
   "metadata": {
    "id": "45541914"
   },
   "outputs": [],
   "source": [
    "def mu_np(X):\n",
    "    x, y, z = np.split(X, dim, axis=-1)\n",
    "    p = alpha * (y - x)\n",
    "    q = x * (rho - z) - y\n",
    "    r = x * y - beta * z\n",
    "    return np.concatenate([p, q, r], axis=-1)\n",
    "\n",
    "sigma = 10.\n",
    "sigma_h = 5.\n",
    "\n",
    "l = np.ones(dim, dtype=DTYPE)\n",
    "g1 = tfd.MultivariateNormalDiag(loc=2.*l, scale_diag=l)\n",
    "g2 = tfd.MultivariateNormalDiag(loc=-2.*l, scale_diag=l)\n",
    "mix = 0.5\n",
    "rv0 = tfd.Mixture(cat=tfd.Categorical(probs=[mix, 1.-mix]), components=[g1, g2])\n",
    "log_p0 = lambda x: tf.reshape(rv0.log_prob(x), (-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bcd540",
   "metadata": {
    "id": "e8bcd540"
   },
   "source": [
    "#### Define observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0c09ebe",
   "metadata": {
    "id": "d0c09ebe"
   },
   "outputs": [],
   "source": [
    "def H(X):\n",
    "    x, y, z = np.split(X, 3, axis=-1)\n",
    "    return np.concatenate([x, z], axis=-1)\n",
    "\n",
    "def obs(X):\n",
    "    x, y, z = np.split(X, 3, axis=-1)\n",
    "    x = x + np.random.normal(scale=sigma_h, size=x.shape).astype(DTYPE)\n",
    "    z = z + np.random.normal(scale=sigma_h, size=z.shape).astype(DTYPE)\n",
    "    return np.concatenate([x, z], axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f343232",
   "metadata": {
    "id": "4f343232"
   },
   "source": [
    "#### Set up resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e35a7866",
   "metadata": {
    "id": "e35a7866"
   },
   "outputs": [],
   "source": [
    "def get_weights(y, X):\n",
    "    rv1 = tfd.MultivariateNormalDiag(loc=y, scale_diag=sigma_h*np.ones(len(y)).astype(DTYPE))\n",
    "    w = rv1.prob(H(X)).numpy()\n",
    "    return w/w.sum()\n",
    "\n",
    "@ut.timer\n",
    "def systematic_noisy_resample(X, weights, resampling_cov=0.1):\n",
    "        # make N subdivisions, and choose positions with a consistent random offset\n",
    "        positions = (np.random.random() + np.arange(n_particles)) / n_particles\n",
    "        indices = np.zeros(n_particles, 'i')\n",
    "        cumulative_sum = np.cumsum(weights.astype('float64'))\n",
    "        i, j = 0, 0\n",
    "\n",
    "        while i < n_particles:\n",
    "            if positions[i] < cumulative_sum[j]:\n",
    "                indices[i] = j\n",
    "                i += 1\n",
    "            else:\n",
    "                j += 1\n",
    "        indices = list(set(indices))\n",
    "        offsprings = [0] * len(indices)\n",
    "        weight_sum = sum([weights[i] for i in indices])\n",
    "        for k, i in enumerate(indices):\n",
    "            offsprings[k] = math.ceil(weights[i]/weight_sum*n_particles)\n",
    "        new_particles = np.zeros((sum(offsprings), dim))\n",
    "        mean = np.zeros(dim)\n",
    "        cov = resampling_cov * np.identity(dim)\n",
    "        j = 0\n",
    "        for k, i in enumerate(indices):\n",
    "            new_particles[j] = X[i]\n",
    "            new_particles[j+1: j+offsprings[k]]= X[i] + np.random.multivariate_normal(mean, cov, size=offsprings[k] - 1)\n",
    "            j += offsprings[k]\n",
    "        particles = np.array([new_particles[i] for i in np.random.choice(sum(offsprings), n_particles, replace=False)])\n",
    "        return particles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890b515f",
   "metadata": {
    "id": "890b515f"
   },
   "source": [
    "#### Load true trajectory and observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "836f4677",
   "metadata": {
    "id": "836f4677"
   },
   "outputs": [],
   "source": [
    "true_state = np.load('{}/true_state.npy'.format(save_folder)).astype(DTYPE)\n",
    "observation = np.load('{}/observation.npy'.format(save_folder)).astype(DTYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6123512b",
   "metadata": {
    "id": "6123512b"
   },
   "source": [
    "#### Run trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cda2dfe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8cda2dfe",
    "outputId": "ceb034ad-9090-43f8-83db-3caf974b4779"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken by propagate is 34.1965274810791 seconds\n"
     ]
    }
   ],
   "source": [
    "mc = sim.MCProb(save_folder, n_subdivs, mu_np, sigma, rv0.sample(n_particles).numpy())\n",
    "mc.propagate(n_steps, dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7ffd7d",
   "metadata": {
    "id": "6a7ffd7d"
   },
   "outputs": [],
   "source": [
    "X = np.genfromtxt('{}/ensemble.csv'.format(mc.save_folder), delimiter=',').astype(DTYPE)\n",
    "weights = get_weights(observation[0], X)\n",
    "X_r = systematic_noisy_resample(X, weights, 0.5)\n",
    "pd.DataFrame(X_r).to_csv('{}/ensemble.csv'.format(mc.save_folder), index=None, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c830af",
   "metadata": {
    "id": "57c830af"
   },
   "source": [
    "#### Do box counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed131123",
   "metadata": {
    "id": "ed131123"
   },
   "outputs": [],
   "source": [
    "mc.set_grid(lims=None)\n",
    "mc.assign_pts()\n",
    "p_1f = mc.compute_p2(0, 1, save=False)\n",
    "np.save(save_folder + '/p_1f.npy', p_1f)\n",
    "p_2f = mc.compute_p2(1, 2, save=False)\n",
    "np.save(save_folder + '/p_2f.npy', p_2f)\n",
    "p_3f = mc.compute_p2(2, 0, save=False)\n",
    "np.save(save_folder + '/p_3f.npy', p_3f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3835caa3",
   "metadata": {
    "id": "3835caa3"
   },
   "source": [
    "#### Save grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddaa1654",
   "metadata": {
    "id": "ddaa1654"
   },
   "outputs": [],
   "source": [
    "low = mc.grid.mins\n",
    "high = mc.grid.maxs\n",
    "x = np.linspace(low[0], high[0], num=n_subdivs+1)[:-1].astype(DTYPE) + mc.grid.h[0]/2.\n",
    "y = np.linspace(low[1], high[1], num=n_subdivs+1)[:-1].astype(DTYPE) + mc.grid.h[1]/2.\n",
    "z = np.linspace(low[2], high[2], num=n_subdivs+1)[:-1].astype(DTYPE) + mc.grid.h[2]/2.\n",
    "np.save('{}/x.npy'.format(save_folder), x)\n",
    "np.save('{}/y.npy'.format(save_folder), y)\n",
    "np.save('{}/z.npy'.format(save_folder), z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3c2f26",
   "metadata": {
    "id": "8d3c2f26"
   },
   "outputs": [],
   "source": [
    "observation[0]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "include_colab_link": true,
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
