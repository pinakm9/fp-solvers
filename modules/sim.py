from typing import Any
from matplotlib import projections
import tensorflow as tf
import numpy as np 
import time
import pandas as pd
import utility as ut
import matplotlib.pyplot as plt
from matplotlib.animation import FuncAnimation
import integrator as it

DTYPE = 'float32'


class Grid:
    """
    A class for collecting grid data for MC simulation

    Attributes:
        dim: dimension of the grid
        mins: array of lower bounds for the grid
        maxs: array of upper bounds for the grid 
        h: array of step sizes in every dimension 
        dV: volume of smallest cube in the grid
    """
    def __init__(self, dim):
        self.dim = dim
        self.mins = np.zeros(dim)
        self.maxs = np.zeros(dim) 
        self.h = np.zeros(dim)
        self.dV = np.prod(self.h)


class MCProb:
    """
    A class for computing Monte Carlo estimate of densities with 
    the SDE of the form dX_t = mu(X_t)dt + sigma x dW_t where X_t is d-dimensional

    Attributes:
        mu: drift in the the SDE 
        sigma: constant diffusion in the SDE 
        X0: initial ensemble 
        save_folder: folder to save the generated data
    """
    def __init__(self, save_folder, n_subdivs, mu=None, sigma=None, X0=None, tick_size=15, title_size=15, cbar_tick_size=10):
        self.X = X0 
        self.mu = mu 
        self.sigma = sigma
        self.save_folder = save_folder
        self.n_subdivs = n_subdivs
        self.n_particles = len(X0)
        self.dim = X0.shape[-1]
        self.grid = Grid(dim=self.dim)
        self.total_sims = self.n_particles
        self.tick_size = tick_size
        self.cbar_tick_size = cbar_tick_size
        self.title_size = title_size

    @ut.timer
    def propagate(self, n_steps, dt):
        """
        Description: propagates particles according to the SDE and stores the final positions

        Args:
            n_steps: number of steps in Euler-Maruyama
            dt: time-step in Euler-Maruyama
        """
        self.final_time = dt * n_steps
        self.n_steps = n_steps
        start = time.time()
        for step in range(n_steps):
            self.X +=  self.mu(self.X) * dt + self.sigma * np.random.normal(scale=np.sqrt(dt), size=(self.n_particles, self.dim))
            if step%1000 == 0:
                print('step = {}, time taken = {:.4f}'.format(step, time.time() - start), end='\r')
        pd.DataFrame(self.X).to_csv('{}/ensemble.csv'.format(self.save_folder), index=None, header=None)

    def roundup(self, real, n):
        """
        Description: Rounds up a real number to desired number of decimal points

        Args:
            real: a real number to round
            n: required number of decimal points
        """
        real *= 10.**n 
        return np.ceil(real) / (10.**n)
    
    @ut.timer
    def set_grid(self, lims=None):
        """
        Description: Computes shape of the grid generated by the propagation
        """
        pts = np.genfromtxt('{}/ensemble.csv'.format(self.save_folder), delimiter=',')
        if lims is None:
            for d in range(self.dim):
                self.grid.mins[d], self.grid.maxs[d] = self.roundup(min(pts[:, d]), 2), self.roundup(max(pts[:, d]), 2)
            min_max = np.array(list(zip(self.grid.mins, self.grid.maxs)))
        else:
            min_max = np.array(lims).T
            new_pts = []
            for pt in pts:
                a = pt - min_max.T[0]
                b = min_max.T[1] - pt 
                c = a * b
                if c[0] > 0. and c[1] > 0. and c[2] > 0.:
                    new_pts.append(pt) 
            pd.DataFrame(np.array(new_pts)).to_csv('{}/ensemble.csv'.format(self.save_folder), index=None, header=None)
        pd.DataFrame(min_max).to_csv('{}/min_max.csv'.format(self.save_folder), index=None, header=None)


    def get_grid(self):
        """
        Description: Reads the pre-computed grid 
        """
        min_max = np.genfromtxt('{}/min_max.csv'.format(self.save_folder), delimiter=',')
        for d in range(self.dim):
            self.grid.mins[d], self.grid.maxs[d] = min_max[d]
        
        self.grid.h = (self.grid.maxs - self.grid.mins) / self.n_subdivs
        self.grid.dV = np.prod(self.grid.h)
        return self.grid


    @ut.timer
    def assign_pts(self):
        """
        Description: Assigns the generated points to the grid boxes
        """
        pts = np.genfromtxt('{}/ensemble.csv'.format(self.save_folder), delimiter=',')
        self.get_grid()
        coords = ((pts - self.grid.mins) / self.grid.h).astype(int)
        pd.DataFrame(coords).to_csv('{}/coordinates.csv'.format(self.save_folder), index=None, header=None)

    
    @ut.timer
    def compute_pd(self):
        """
        Description: Computes probability in each box in the grid
        """
        coords = np.genfromtxt('{}/coordinates.csv'.format(self.save_folder), delimiter=',')
        boxes, counts = np.unique(coords, return_counts=True, axis=0)
        
        pd.DataFrame(boxes).to_csv('{}/boxes.csv'.format(self.save_folder), index=None, header=None)
        pd.DataFrame(counts).to_csv('{}/counts.csv'.format(self.save_folder), index=None, header=None)

        self.get_grid()
        centers = self.grid.mins + boxes * self.grid.h + self.grid.h / 2.
        probs = counts / (self.total_sims * self.grid.dV)
        idx = np.argsort(probs)

        pd.DataFrame(centers[idx][::-1]).to_csv('{}/centers.csv'.format(self.save_folder), index=None, header=None)
        pd.DataFrame(probs[idx][::-1]).to_csv('{}/center_probs.csv'.format(self.save_folder), index=None, header=None)


    @ut.timer
    def compute_p2(self, i, j, save=True):
        """
        Description: Computes probability for each box in a two-dimensional grid

        Args:
            i: index specifying the first dimension
            j: index specifying the second dimension
        """
        coords = np.genfromtxt('{}/coordinates.csv'.format(self.save_folder), delimiter=',')
        boxes, counts = np.unique(coords[:, [i, j]], return_counts=True, axis=0)
        pd.DataFrame(boxes).to_csv('{}/boxes_{}_{}.csv'.format(self.save_folder, i, j), index=None, header=None)
        pd.DataFrame(counts).to_csv('{}/counts_{}_{}.csv'.format(self.save_folder, i, j), index=None, header=None)

        self.get_grid()
        x = np.linspace(self.grid.mins[i], self.grid.maxs[i], num=self.n_subdivs+1)[1:]
        y = np.linspace(self.grid.mins[j], self.grid.maxs[j], num=self.n_subdivs+1)[1:]
        prob = np.zeros((self.n_subdivs, self.n_subdivs))
        
        for k, b in enumerate(boxes):
            prob[int(b[0]), int(b[1])] = counts[k] 

        prob /= (np.sum(prob) * self.grid.h[i] * self.grid.h[j])
        if not save:
            return prob
        x, y = np.meshgrid(x, y)
        
        fig = plt.figure(figsize=(8, 8))
        ax = fig.add_subplot(111)
        im = ax.pcolormesh(x, y, prob, cmap='inferno_r', shading='auto')
        cbar = fig.colorbar(im)
        cbar.ax.tick_params(labelsize=self.cbar_tick_size)
        ax.set_xlabel(r'$x_{}$'.format(i))
        ax.set_ylabel(r'$x_{}$'.format(j))
        def get_char(c):
            if c == 0:
                return 'x'
            elif c == 1:
                return 'y'
            elif c == 2:
                return 'z'

        ax.set_title(r'MC estimate of $p({}, {})$ at time = {:.4f}'.format(get_char(i), get_char(j), self.final_time), fontsize=self.title_size)
        ax.tick_params(axis='both', which='major', labelsize=self.tick_size)
        ax.tick_params(axis='both', which='minor', labelsize=self.tick_size)
        plt.tight_layout()
        plt.savefig('{}/p_{}_{}_mc_steps_{}.png'.format(self.save_folder, i, j, self.n_steps))
        plt.close(fig)
        


    @ut.timer
    def compute_p1(self, i):
        """
        Description: Computes probability for each interval in a one-dimensional grid

        Args:
            i: index specifying the dimension
        """
        coords = np.genfromtxt('{}/coordinates.csv'.format(self.save_folder), delimiter=',')
        boxes, counts = np.unique(coords[:, i], return_counts=True, axis=0)
        pd.DataFrame(boxes).to_csv('{}/boxes_{}.csv'.format(self.save_folder, i), index=None, header=None)
        pd.DataFrame(counts).to_csv('{}/counts_{}.csv'.format(self.save_folder, i), index=None, header=None)

        self.get_grid()
        x = np.linspace(self.grid.mins[i], self.grid.maxs[i], num=self.n_subdivs+1)[1:]
        prob = np.zeros(self.n_subdivs)
        for k, b in enumerate(boxes):
            prob[int(b)] = counts[k]

        prob /= np.sum(prob) * self.grid.h[i]
        fig = plt.figure(figsize=(8, 8))
        ax = fig.add_subplot(111)
        ax.plot(x, prob)
        ax.set_xlabel(r'$x_{}$'.format(i))
        ax.set_ylabel(r'$p(x_{})$'.format(i))
        ax.set_title(r'MC estimate of $p(x_{})$ at time = {:.2f}'.format(i, self.final_time))
        plt.tight_layout()
        plt.savefig('{}/p_{}_mc_steps_{}.png'.format(self.save_folder, i, self.n_steps))
        plt.close(fig) 
    

    @ut.timer
    def ready(self, n_steps, dt, lims=None):
        """
        Description: Prepares the MCProb object for computing the probability densities.

        Args:
            n_steps: number of steps to propagate the particles
            dt: time step size
            lims: limits of the grid in each dimension
        """
        self.propagate(n_steps, dt)
        self.set_grid(lims)
        self.assign_pts()

    @ut.timer
    def compute_all(self, n_steps, dt, lims=None):
        """
        Description: Computes all d, 2 and 1 dimensional densities

        Args:
            n_steps: number of steps in Euler-Maruyama
            dt: time-step in Euler-Maruyama
        """
        self.ready(n_steps, dt, lims=None)
        self.compute_pd()
        for i in range(self.dim):
            self.compute_p1(i)
            for j in range(i+1, self.dim):
                self.compute_p2(i, j)



    @ut.timer
    def get_slice_pts(self, dims=[0, 1], levels={2: 0.}, eps=0.1):
        pts = np.genfromtxt('{}/ensemble.csv'.format(self.save_folder), delimiter=',')
        for i in levels:
            idx = np.where(pts[:, i] < levels[i] + eps)[0]
            pts = pts[idx, :]
            idx = np.where(pts[:, i] > levels[i] - eps)[0]
            pts = pts[idx, :]
        return pts 

    @ut.timer
    def slice2D(self, dims=[0, 1], levels={2: 0.}, eps=0.1):
        """
        Description: Computes probability on a 2D slice

        Args:
            dims: indices specifying the 2D slice
            levels: values of rest of the dimensions 
            eps: leeway in the rest of the dimensions
        """
        pts = self.get_slice_pts(dims, levels, eps)
        self.get_grid()
        i, j = sorted(dims)
        x = np.linspace(self.grid.mins[i], self.grid.maxs[i], num=self.n_subdivs+1)
        y = np.linspace(self.grid.mins[j], self.grid.maxs[j], num=self.n_subdivs+1)
        prob = np.zeros((self.n_subdivs, self.n_subdivs))
        coords = ((pts - self.grid.mins) / self.grid.h).astype('float32')
        boxes, counts = np.unique(coords[:, [i, j]], return_counts=True, axis=0)
        

        for k, b in enumerate(boxes):
            prob[int(b[0]), int(b[1])] = counts[k] 

        prob /= np.sum(prob)
        x, y = np.meshgrid(x, y)
        fig = plt.figure(figsize=(8, 8))
        ax = fig.add_subplot(111)
        im = ax.pcolormesh(x, y, prob, cmap='inferno_r', shading='auto')
        fig.colorbar(im)
        ax.set_xlabel(r'$x_{}$'.format(i))
        ax.set_ylabel(r'$x_{}$'.format(j))
        ax.set_title(r'MC estimate of $p(x_{}, x_{})$ at time = {:.4f}'.format(i, j, self.final_time))
        plt.tight_layout()
        plt.savefig('{}/p_slice_{}_{}_mc_steps_{}.png'.format(self.save_folder, i, j, self.n_steps))
        plt.close(fig)

    def slice_all(self, levels={0: 0., 1: 0., 2: 0.}, eps=0.1):
        for i in range(3):
            dims =  [(i+1)%3, (i+2)%3]
            self.slice2D(dims=dims, levels={i: levels[i]}, eps=eps)
    




class FK32:
    """
    Description: Feynman-Kac simulation for a 2D grid taking integration 
    in the other dimension into consideration
    """
    def __init__(self, save_folder, n_subdivs, n_int_subdivs, mu, sigma, n_theta, grid, log_p0, dtype='float32', max_comp=1e5):
        """
        Initializes the Feynman-Kac simulation object.

        Parameters:
            save_folder (str): Directory path to save simulation results.
            n_subdivs (int): Number of subdivisions for the grid in each dimension.
            n_int_subdivs (int): Number of subdivisions for the integration grid in each dimension.
            mu (callable): The drift function for the stochastic process.
            sigma (float): The diffusion coefficient for the stochastic process.
            n_theta (int): Trained neural network representing the log of the steady state.
            grid (Grid): The grid object.
            log_p0 (callable): The logarithm of the stationary distribution.
            dtype (str): The data type for the simulation. Default is 'float32'.
            max_comp (int): The maximum number of points to evaluate the network on. Should be tailored according to the GPU memory. Default is 1e5.
        """
        self.grid = grid 
        self.mu = mu 
        self.sigma = sigma
        self.net = n_theta
        self.n_int_subdivs = n_int_subdivs 
        self.n_subdivs = n_subdivs
        self.log_p0 = log_p0
        self.dtype = dtype
        self.save_folder = save_folder
        self.dim = 3
        self.max_comp = int(max_comp)

    def h0(self, X):
        """
        Computes the initial condition for the Feynman-Kac simulation.

        Parameters:
            X (numpy array): The points to evaluate the initial condition on.

        Returns:
            numpy array: The initial condition evaluated on X.
        """
        m = self.max_comp
        M = int(np.ceil(len(X) / m))
        data = []
        for i in range(M):
            if i < M-1:
                x = X[i*m: (i+1)*m]
            else:
                x = X[i*m:]
            log_p0 = self.log_p0(x).numpy()#(- (x**2 + y**2 + z**2) / (2.*r**2)).numpy()
            log_pinf = self.net(x).numpy()
            data.append(np.exp(log_p0 - log_pinf)) #/ (2. * np.pi * r**2) ** (1.5))  
        return np.concatenate(data, axis=0) 

    def p_inf(self, X):
        """
        Computes the steady state using the trained neural network.

        Parameters:
            X (numpy array): The points to evaluate the steady state on.

        Returns:
            numpy array: The steady state evaluated on X.
        """
        m = self.max_comp
        M = int(np.ceil(len(X) / m))
        data = []
        for i in range(M):
            if i < M-1:
                x = X[i*m: (i+1)*m]
            else:
                x = X[i*m:] 
            data.append(np.exp(self.net(x)))
        return np.concatenate(data, axis=0)

    @tf.function
    def h_mu(self, X):
        """
        Computes the drift term of the h-SDE.

        This function calculates the h-drift term using the neural network's 
        gradient and the given drift function mu.

        Parameters:
            X (tf.Tensor): A tensor of shape (N, 3) where N is the number of 
                        samples, representing the input data consisting of 
                        x, y, z coordinates.

        Returns:
            tf.Tensor: The computed h-drift term as a tensor of the same shape
                    as the input X.
        """

        x, y, z = tf.split(X, [1, 1, 1], axis=-1)
        with tf.GradientTape() as tape:
            tape.watch([x, y, z])
            n_ = self.net(x, y, z) 
        grad_n = tf.concat(tape.gradient(n_, [x, y, z]), axis=-1)
        return self.sigma**2*grad_n - self.mu(X)
    
    #@tf.function
    def get_endpt(self, n_steps, dt, X, dW): 
        """
        This function integrates the h-SDE from given initial conditions X with given noise dW.
        
        Parameters:
            n_steps (int): The number of time steps to integrate for.
            dt (float): The time step size.
            X (tf.Tensor): The initial conditions of the stochastic process.
            dW (tf.Tensor): The noise to be added to the stochastic process.
        
        Returns:
            tf.Tensor: The integrated stochastic process at the end of the time steps.
        """
        m = self.max_comp
        M = int(np.ceil(len(X) / m))
        data = []
        for i in range(M):
            for step in range(n_steps):
                if i < M-1:
                    x = X[i*m: (i+1)*m]
                    noise = dW[step][i*m: (i+1)*m]
                else:
                    x = X[i*m:]
                    noise = dW[step][i*m:]
                x += self.h_mu(x).numpy() * dt + self.sigma * noise
            data.append(x)
        return np.concatenate(data, axis=0)
    
    @ut.timer
    def set_filter(self, i, j, z):
        """
        Configures the filter by setting up rectangular boxes and mapping z-values.

        Args:
            i (int): Index specifying the first dimension.
            j (int): Index specifying the second dimension.
            z (array-like): Array of z-values to map.

        Loads an ensemble from a file and divides the space into rectangular boxes
        based on the grid dimensions. Computes box coordinates for each point in the
        ensemble and removes duplicates. Maps the z-values to a uniform grid for further
        processing.
        """

        k = list({0, 1, 2}-{i, j})[0]
        # load the ensemble
        pts = np.genfromtxt(self.filter, delimiter=',')
        # set up rectangular boxes 
        mins = np.array([self.grid.mins[i], self.grid.mins[j], self.grid.mins[k]]).astype(self.dtype)
        hi = (self.grid.maxs[i] - self.grid.mins[i]) / self.n_subdivs
        hj = (self.grid.maxs[j] - self.grid.mins[j]) / self.n_subdivs
        hk = (self.grid.maxs[k] - self.grid.mins[k]) / self.n_int_subdivs
        h = np.array([hi, hj, hk]).astype(self.dtype)
        # find box coordinates for every point
        self.boxes = ((pts[:, [i, j, k]] - mins) / h).astype(int)
        # remove repeating coordinates
        self.boxes = np.unique(self.boxes, axis=0)
        # sort boxes coordinates by z-value
        #self.boxes = self.boxes[self.boxes[:, 2].argsort()]
        # print(self.boxes)
        # non-uniform to uniform zmap
        self.zmap = ((z.flatten() - mins[2]) / h[2]).astype(int)
        # print('boxes = {}'.format(self.boxes))
        # print('zmap = {}'.format(self.zmap))

    def prune_z(self, m, n, z, w):
        """
        Removes z values that do not contribute to the probability calculation.

        Parameters:
            m (int): Index specifying the first dimension.
            n (int): Index specifying the second dimension.
            z (tf.Tensor): The z values to prune.
            w (tf.Tensor): The weights to prune.

        Returns:
            tf.Tensor, tf.Tensor: The pruned z values and weights.
        """
        # # find z indices that contribute
        good_z = self.boxes[np.where((self.boxes[:, 0] == m) * (self.boxes[:, 1] == n))][:,-1] #np.unique(self.boxes[:, 2], axis=0)#
        # print('good_z = {}, {}, {}'.format(m, n, good_z))
        # convert to z values using zmap
        zl = list(z)
        wl = list(w)
        for i in range(len(z)-1, -1, -1): # pop indices in reversed order
            if self.zmap[i] not in good_z:
                zl.pop(i)
                wl.pop(i)
        
        if len(zl) > 1:
            z_ = np.array(zl).astype(self.dtype).reshape(-1, 1)
            w_ = np.array(wl).astype(self.dtype).reshape(-1, 1)
            return z_, w_
        else:
            return z.reshape(-1, 1), w.reshape(-1, 1)
     


    @ut.timer
    def calc_2D_prob(self, n_steps, dt, n_repeats, i, j, filter, method, prune=True, **kwargs):
        """
        Description: calculates 2D marginal pdf for 3D system after using Feynaman-Kac to estimate the full pdf

        Args:
            n_steps: number of steps in Euler-Maruyama
            dt: time-step in Euler-Maruyama
            n_repeats: number of simulations per grid point
            i: x dimension
            j: y dimension 
            k: dimension to be integrated out
            filter: None or path to reference ensemble for filtering
            method: quadrature method
            **kwargs: keyword arguments for quadrature
        """
        k = list({0, 1, 2}-{i, j})[0]
        x = np.linspace(self.grid.mins[i], self.grid.maxs[i], num=self.n_subdivs+1).astype(self.dtype)[1:] + self.grid.h[i]/2.
        y = np.linspace(self.grid.mins[j], self.grid.maxs[j], num=self.n_subdivs+1).astype(self.dtype)[1:] + self.grid.h[j]/2.
        
        # set up integration
        domain = [self.grid.mins[k], self.grid.maxs[k]]
        num = kwargs['num']
        if method == "Trapezoidal":
            q = it.Trapezoidal(domain, num, self.dtype)
        elif method == "Simpson_1_3":
            q = it.Simpson_1_3(domain, num, self.dtype)
        elif method == "Simpson_3_8":
            q = it.Simpson_3_8(domain, num, self.dtype)
        elif method == "Gauss_Legendre":
            q = it.Gauss_Legendre(domain, num, kwargs['d'], self.dtype)
         
        prob = np.zeros((self.n_subdivs, self.n_subdivs))
        self.n_steps = n_steps
        self.final_time = dt * n_steps
        start = time.time()
     
        self.filter = filter
        if isinstance(filter, str):
            self.set_filter(i, j, q.nodes)
            nonzero_boxes = np.unique(self.boxes[:, [0, 1]], axis=0)
        elif isinstance(filter,  list):
            nonzero_boxes = filter
        else:
            nonzero_boxes = [(m, n) for m in range(self.n_subdivs) for n in range(self.n_subdivs)]

        if not prune:
            z, w = q.nodes.reshape(-1, 1), q.weights.reshape(-1, 1)
        
        for m, n in nonzero_boxes:
            if prune:
                z, w = self.prune_z(m, n, q.nodes, q.weights)
            ones = tf.ones_like(z)
            X0 = tf.concat([e for _, e in sorted(zip([i, j, k], [x[m]*ones, y[n]*ones, z]))], axis=-1).numpy()
            X = np.repeat(X0, repeats=n_repeats, axis=0)
            dW = np.random.normal(scale=np.sqrt(dt), size=(n_steps, X.shape[0], 3)).astype(self.dtype)
            X = self.get_endpt(n_steps, dt, X, dW)
            print('grid_index = {}, time taken = {:.4f}'.format((m, n), time.time() - start))
            h0 = tf.reduce_mean(self.h0(X).reshape((-1, n_repeats)), axis=-1, keepdims=True).numpy()
            prob[m][n] = (w*h0*self.p_inf(X0)).sum()
        return prob
    

    @ut.timer
    def calc_2D_prob_weighted(self, n_steps, dt, n_repeats, i, j, filter, method, weight, prune=True, **kwargs):
        """
        Description: calculates 2D marginal pdf for 3D system after using Feynaman-Kac to estimate the full pdf. 
        A weight w function can be used to modify the resulting pdf p into pw/Z where Z is the normalizing constant, 
        useful for filtering experiments. 

        Args:
            n_steps: number of steps in Euler-Maruyama
            dt: time-step in Euler-Maruyama
            n_repeats: number of simulations per grid point
            i: x dimension
            j: y dimension 
            k: dimension to be integrated out
            filter: None or path to reference ensemble for filtering
            method: quadrature method
            weight: weight function e.g. in the context of filtering a likelihood function
            **kwargs: keyword arguments for quadrature
        """
        k = list({0, 1, 2}-{i, j})[0]
        x = np.linspace(self.grid.mins[i], self.grid.maxs[i], num=self.n_subdivs+1).astype(self.dtype)[1:] + self.grid.h[i]/2.
        y = np.linspace(self.grid.mins[j], self.grid.maxs[j], num=self.n_subdivs+1).astype(self.dtype)[1:] + self.grid.h[j]/2.
        
        # set up integration
        domain = [self.grid.mins[k], self.grid.maxs[k]]
        num = kwargs['num']
        if method == "Trapezoidal":
            q = it.Trapezoidal(domain, num, self.dtype)
        elif method == "Simpson_1_3":
            q = it.Simpson_1_3(domain, num, self.dtype)
        elif method == "Simpson_3_8":
            q = it.Simpson_3_8(domain, num, self.dtype)
        elif method == "Gauss_Legendre":
            q = it.Gauss_Legendre(domain, num, kwargs['d'], self.dtype)
         
        prob = np.zeros((self.n_subdivs, self.n_subdivs))
        self.n_steps = n_steps
        self.final_time = dt * n_steps
        start = time.time()
     
        self.filter = filter
        if isinstance(filter, str):
            self.set_filter(i, j, q.nodes)
            nonzero_boxes = np.unique(self.boxes[:, [0, 1]], axis=0)
        elif isinstance(filter,  list):
            nonzero_boxes = filter
        else:
            nonzero_boxes = [(m, n) for m in range(self.n_subdivs) for n in range(self.n_subdivs)]

        if not prune:
            z, w = q.nodes.reshape(-1, 1), q.weights.reshape(-1, 1)
        
        for m, n in nonzero_boxes:
            if prune:
                z, w = self.prune_z(m, n, q.nodes, q.weights)
            ones = tf.ones_like(z)
            X0 = tf.concat([e for _, e in sorted(zip([i, j, k], [x[m]*ones, y[n]*ones, z]))], axis=-1).numpy()
            X = np.repeat(X0, repeats=n_repeats, axis=0)
            dW = np.random.normal(scale=np.sqrt(dt), size=(n_steps, X.shape[0], 3)).astype(self.dtype)
            X = self.get_endpt(n_steps, dt, X, dW)
            print('grid_index = {}, time taken = {:.4f}'.format((m, n), time.time() - start))
            Eh0 = tf.reduce_mean(self.h0(X).reshape((-1, n_repeats)), axis=-1, keepdims=True).numpy()
            prob[m][n] = (w*Eh0*self.p_inf(X0)*weight(X0)).sum()
        return prob







        
        
    
    

    



















class Evolution:
    """
    Class for visualizing evolution of an SDE
    """

    def __init__(self, save_folder, mu, sigma) -> None:
        self.mu = mu 
        self.sigma = sigma
        self.save_folder = save_folder

    @ut.timer
    def propagate(self, n_steps, dt, X0):
        self.dt = dt
        self.dim = X0.shape[-1]
        self.n_particles = X0.shape[0]
        self.X = np.zeros((n_steps + 1, self.n_particles, self.dim)).astype(DTYPE)
        self.X[0, :, :] = X0
        dW = np.random.normal(scale=np.sqrt(dt), size=(n_steps, self.n_particles, self.dim)).astype(DTYPE)
        start = time.time()
        for step in range(n_steps):
            self.X[step+1, :, :] = self.X[step, :, :] + self.mu(self.X[step, :, :]) * dt + self.sigma * dW[step, :, :]
            if step%1000 == 0:
                print('step = {}, time taken = {:.4f}'.format(step, time.time() - start), end='\r')
        np.save('{}/evolution.npy'.format(self.save_folder), self.X)


    def final_state(self, idx=[0, 1, 2]):
        """
        Description:
            Animates evolution of an ensemble
        
        Args:
            idx: dimensions to plot
        """
        fig = plt.figure(figsize=(8, 8))
        if len(idx) > 2:
            ax = fig.add_subplot(111, projection='3d')
            p, q, r = idx[:3]
            ax.scatter(self.X[-1, :, p], self.X[-1, :, q], self.X[-1, :, r])
            ax.set_xlabel(r'$x_{}$'.format(p))
            ax.set_ylabel(r'$x_{}$'.format(q))
            ax.set_zlabel(r'$x_{}$'.format(r))
        else:
            ax = fig.add_subplot(111)
            p, q = idx[:2]
            ax.scatter(self.X[-1, :, p], self.X[-1, :, q])
            ax.set_xlabel(r'$x_{}$'.format(p))
            ax.set_ylabel(r'$x_{}$'.format(q))
        
        ax.set_title('time = {:.3f}'.format((len(self.X) - 1) * self.dt))
        plt.savefig(self.save_folder + '/final_state.png')
        

    @ut.timer
    def animate(self, idx=[0, 1, 2], n_frames=100, max_pts=500):
        """
        Description:
            Animates evolution of an ensemble
        
        Args:
            idx: dimensions to plot
            n_frames: number of frames to plot
        """
        fig = plt.figure(figsize=(8, 8))
        if len(idx) > 2:
            ax = fig.add_subplot(111, projection='3d')
            p, q, r = idx[:3]
        else:
            ax = fig.add_subplot(111)
            p, q = idx[:2]

        n_pts = min(self.X.shape[1], max_pts)
        def animator(j):
            ax.clear()
            if len(idx) > 2:
                ax.scatter(self.X[j, :n_pts, p], self.X[j, :n_pts, q], self.X[j, :n_pts, r])
            else:
                ax.scatter(self.X[j, :n_pts, p], self.X[j, :n_pts, q])
            ax.set_title('time = {:.3f}'.format(j * self.dt))

        a = int(self.X.shape[0] / n_frames)
        frames = [f for f in range(self.X.shape[0]) if f%a == 0]
        animation = FuncAnimation(fig=fig, func=animator, frames = frames, interval=50, repeat=False)
        animation.save(self.save_folder + '/evolution.mp4', writer='ffmpeg')

    
    
    def exit_prob(self, domain):
        # check if pints are in the domain
        io = tf.greater((self.X - domain[0]) * (domain[1] - self.X), 0.)
        io = tf.math.reduce_all(io, axis=-1)
        # count points in the domain
        io = np.cumprod(io, axis=0)
        io = np.sum(io, axis=-1) / self.X.shape[1]
     

        fig = plt.figure(figsize=(8, 8))
        ax = fig.add_subplot(111)
        t = [e*self.dt for e in range(len(io))]
        ax.plot(t, 1.0 - io)
        ax.set_ylabel('exit probability')
        ax.set_xlabel('time')
        plt.savefig(self.save_folder + '/exit_prob.png')
        


class Exit:
    def __init__(self, mu, sigma, start_domain, end_domain, save_folder, tag='', dtype='float32', max_comp=int(1e4)):
        self.mu = mu
        self.sigma = sigma
        self.start_domain = np.array(start_domain)
        self.end_domain = np.array(end_domain)
        self.save_folder = save_folder
        self.dim = len(self.start_domain[0])
        self.tag = tag
        self.dtype = dtype
        self.max_comp = max_comp


    @ut.timer
    def generate_trajectories(self, num, dt, n_steps, net=None, grid=False):
        if net is not None:
            self.net = net
            mu = lambda X: self.h_mu(X)
            self.dtype = net.dtype
        else:
            mu = self.mu
        
        if grid:
            X = np.zeros((n_steps+1, int(num**self.dim), self.dim)).astype(self.dtype)
            x = np.linspace(self.start_domain[0][0], self.start_domain[1][0], num=num).astype(self.dtype)
            y = np.linspace(self.start_domain[0][1], self.start_domain[1][1], num=num).astype(self.dtype)
            if self.dim == 3: 
                z = np.linspace(self.start_domain[0][2], self.start_domain[1][2], num=num).astype(self.dtype)
                x, y, z = np.meshgrid(x, y, z)
                X[0, :, :] = np.concatenate([x.reshape(-1, 1), y.reshape(-1, 1), z.reshape(-1, 1)], axis=-1)
            else:
                x, y = np.meshgrid(x, y)
                X[0, :, :] = np.concatenate([x.reshape(-1, 1), y.reshape(-1, 1)], axis=-1)
        else:
            X = np.zeros((n_steps+1, num, self.dim)).astype(self.dtype)
            X[0, :, :] = np.random.uniform(low=self.start_domain[0], high=self.start_domain[1], size=(num, self.dim)).astype(self.dtype)
        dW = np.random.normal(scale=np.sqrt(dt), size=(n_steps, X.shape[1], self.dim)).astype(self.dtype)
        m = self.max_comp
        M = int(np.ceil(X.shape[1] / m))
        for step in range(n_steps):
            for i in range(M):
                if i < M-1:
                    x = X[step, i*m: (i+1)*m, :]
                    noise = dW[step, i*m: (i+1)*m, :]
                    X[step+1, i*m: (i+1)*m, :] = x + mu(x).numpy() * dt + self.sigma * noise
                else:
                    x = X[step, i*m:, :]
                    noise = dW[step, i*m:, :]
                    X[step+1, i*m:, :] = x + mu(x).numpy() * dt + self.sigma * noise
        np.save('{}/{}_exit_trajectories.npy'.format(self.save_folder, self.tag), X)
        self.n_steps = n_steps
        self.dt = dt
        self.num = num

    # @tf.function
    def h_mu(self, X):
        args = tf.split(X, self.dim, axis=-1)
        with tf.GradientTape() as tape:
            tape.watch(args)
            n_ = self.net(*args) 
        grad_n = tf.concat(tape.gradient(n_, args), axis=-1)
        return self.sigma**2*grad_n - self.mu(X)

    @ut.timer
    def calculate_probability(self):
        self.prob = np.zeros(self.n_steps+1)
        X = np.load('{}/{}_exit_trajectories.npy'.format(self.save_folder, self.tag)).astype(self.dtype)
        self.io = np.zeros((self.n_steps+1, X.shape[1]), dtype=self.dtype) 
        for i in range(self.n_steps+1):
            self.io[i] =  (np.sum(np.sign((X[i]-self.end_domain[0])*(self.end_domain[1]-X[i])), axis=-1)==self.dim)\
                                 .astype(self.dtype)
        for i in range(1, self.n_steps+1):
            self.io[i] *= self.io[i-1]
        self.prob = 1. - np.sum(self.io, axis=-1) / X.shape[1]
        


    @ut.timer
    def get_prob(self, num, dt, n_steps, net, grid):
        self.generate_trajectories(num, dt, n_steps, net, grid)
        self.calculate_probability()

    def update(self, **kwargs):
        for key in kwargs:
            setattr(self, key, kwargs[key])


    @ut.timer
    def generate_trajectories_2(self, n_pts, n_reps, n_steps, dt, net=None):
        if net is not None:
            self.net = net
            mu = lambda X: self.h_mu(X)
            self.dtype = net.dtype
        else:
            mu = self.mu
        
        io = np.zeros((n_pts, n_reps, n_steps+1))
        X0 = np.random.uniform(low=self.start_domain[0], high=self.start_domain[1], size=(n_pts, self.dim)).astype(self.dtype)
        X = np.zeros((n_pts*n_reps, n_steps+1, self.dim)).astype(self.dtype)
        X[:, 0, :] = np.repeat(X0, n_reps, axis=0)
        dW = np.random.normal(scale=np.sqrt(dt), size=(n_steps, X.shape[0], self.dim)).astype(self.dtype)
        m = self.max_comp
        M = int(np.ceil(X.shape[1] / m))
        for step in range(n_steps):
            for i in range(M):
                if i < M-1:
                    x = X[i*m: (i+1)*m, step, :]
                    noise = dW[step, i*m: (i+1)*m, :]
                    X[i*m: (i+1)*m, step+1, :] = x + mu(x).numpy() * dt + self.sigma * noise
                else:
                    x = X[i*m:, step, :]
                    noise = dW[step, i*m:, :]
                    X[i*m:, step+1, :] = x + mu(x).numpy() * dt + self.sigma * noise
        np.save('{}/{}_exit_trajectories_ptw.npy'.format(self.save_folder, self.tag), X)
        self.n_steps = n_steps
        self.dt = dt
        self.n_pts = n_pts
        self.n_reps = n_reps

    
    @ut.timer
    def calculate_max_probability(self):
        X = np.load('{}/{}_exit_trajectories_ptw.npy'.format(self.save_folder, self.tag))
        io =  (np.sum(np.sign((X-self.end_domain[0])*(self.end_domain[1]-X)), axis=-1)==self.dim).astype(self.dtype)
        pd.DataFrame(io).to_csv('{}/{}_io.csv'.format(self.save_folder, self.tag), index=None, header=None)
        for j in range(1, io.shape[1]):
            io[:, j] *= io[:, j-1]
        pd.DataFrame(io).to_csv('{}/{}_io_final.csv'.format(self.save_folder, self.tag), index=None, header=None)
        io = np.sum(io.reshape(self.n_pts, self.n_reps, io.shape[-1]), axis=1) / self.n_reps
        pd.DataFrame(io).to_csv('{}/{}_io_prob.csv'.format(self.save_folder, self.tag), index=None, header=None)
        pd.DataFrame(np.sum(io, axis=0) / self.n_pts).to_csv('{}/{}_io_prob_all_avg.csv'.format(self.save_folder, self.tag), index=None, header=None)
        pd.DataFrame(np.amin(io, axis=0)).to_csv('{}/{}_io_prob_all_min.csv'.format(self.save_folder, self.tag), index=None, header=None)
        return io


