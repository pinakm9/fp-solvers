{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46356898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pinak\\Documents\\GitHub\\fp-solvers\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "from pathlib import Path\n",
    "script_dir = Path(os.path.dirname(os.path.abspath('')))\n",
    "module_dir = str(script_dir)\n",
    "sys.path.insert(0, module_dir + '/modules')\n",
    "print(module_dir)\n",
    "\n",
    "# import the rest of the modules\n",
    "%matplotlib nbagg\n",
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "import matplotlib.pyplot as plt\n",
    "import sim\n",
    "import pandas as pd\n",
    "import tensorflow_probability as tfp\n",
    "import time  \n",
    "import math\n",
    "import utility as ut\n",
    "tfd = tfp.distributions\n",
    "seed=42\n",
    "np.random.seed(seed=seed)\n",
    "tf.random.set_seed(seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4be9da57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up computation parameters\n",
    "dim = 3\n",
    "n_particles = int(1e5)\n",
    "n_subdivs = 100\n",
    "save_folder = 'L63-pf'\n",
    "n_steps = 3\n",
    "n_repeats = 200\n",
    "dt = 0.01\n",
    "alpha, beta, rho = 10., 8./3., 28.\n",
    "t = dt * n_steps\n",
    "quad_method = 'Gauss_Legendre'\n",
    "n_int_subdivs = 100\n",
    "degree = 6\n",
    "DTYPE = 'float32'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f8afbd",
   "metadata": {},
   "source": [
    "#### Define $\\mu, \\sigma, p_0, \\sigma_h$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45541914",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mu_np(X):\n",
    "    x, y, z = np.split(X, dim, axis=-1)\n",
    "    p = alpha * (y - x) \n",
    "    q = x * (rho - z) - y \n",
    "    r = x * y - beta * z\n",
    "    return np.concatenate([p, q, r], axis=-1)\n",
    "\n",
    "sigma = 10.\n",
    "sigma_h = 5.\n",
    "\n",
    "l = np.ones(dim, dtype=DTYPE)\n",
    "g1 = tfd.MultivariateNormalDiag(loc=2.*l, scale_diag=l)\n",
    "g2 = tfd.MultivariateNormalDiag(loc=-2.*l, scale_diag=l)\n",
    "mix = 0.5\n",
    "rv0 = tfd.Mixture(cat=tfd.Categorical(probs=[mix, 1.-mix]), components=[g1, g2])\n",
    "log_p0 = lambda x: tf.reshape(rv0.log_prob(x), (-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bcd540",
   "metadata": {},
   "source": [
    "#### Define observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0c09ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def H(X):\n",
    "    x, y, z = np.split(X, 3, axis=-1)\n",
    "    return np.concatenate([x, z], axis=-1)\n",
    "\n",
    "def obs(X):\n",
    "    x, y, z = np.split(X, 3, axis=-1)\n",
    "    x = x + np.random.normal(scale=sigma_h, size=x.shape).astype(DTYPE)\n",
    "    z = z + np.random.normal(scale=sigma_h, size=z.shape).astype(DTYPE)\n",
    "    return np.concatenate([x, z], axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f343232",
   "metadata": {},
   "source": [
    "#### Set up resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e35a7866",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights(y, X):\n",
    "    rv1 = tfd.MultivariateNormalDiag(loc=y, scale_diag=sigma_h*np.ones(len(y)).astype(DTYPE))\n",
    "    w = rv1.prob(H(X)).numpy()\n",
    "    return w/w.sum()\n",
    "\n",
    "@ut.timer\n",
    "def systematic_noisy_resample(X, weights, resampling_cov=0.1):\n",
    "        # make N subdivisions, and choose positions with a consistent random offset\n",
    "        positions = (np.random.random() + np.arange(n_particles)) / n_particles\n",
    "        indices = np.zeros(n_particles, 'i')\n",
    "        cumulative_sum = np.cumsum(weights.astype('float64'))\n",
    "        i, j = 0, 0\n",
    "       \n",
    "        while i < n_particles:\n",
    "            if positions[i] < cumulative_sum[j]:\n",
    "                indices[i] = j\n",
    "                i += 1\n",
    "            else:\n",
    "                j += 1\n",
    "        indices = list(set(indices))\n",
    "        offsprings = [0] * len(indices)\n",
    "        weight_sum = sum([weights[i] for i in indices])\n",
    "        for k, i in enumerate(indices):\n",
    "            offsprings[k] = math.ceil(weights[i]/weight_sum*n_particles)\n",
    "        new_particles = np.zeros((sum(offsprings), dim))\n",
    "        mean = np.zeros(dim)\n",
    "        cov = resampling_cov * np.identity(dim)\n",
    "        j = 0\n",
    "        for k, i in enumerate(indices):\n",
    "            new_particles[j] = X[i]\n",
    "            new_particles[j+1: j+offsprings[k]]= X[i] + np.random.multivariate_normal(mean, cov, size=offsprings[k] - 1)\n",
    "            j += offsprings[k]\n",
    "        particles = np.array([new_particles[i] for i in np.random.choice(sum(offsprings), n_particles, replace=False)])\n",
    "        return particles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890b515f",
   "metadata": {},
   "source": [
    "#### Create a true trajectory and observe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "836f4677",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_state = rv0.sample(1).numpy()\n",
    "for step in range(n_steps):\n",
    "    true_state +=  mu_np(true_state) * dt + sigma * np.random.normal(scale=np.sqrt(dt), size=(1, dim))\n",
    "observation = obs(true_state)\n",
    "np.save('{}/true_state.npy'.format(save_folder), true_state)\n",
    "np.save('{}/observation.npy'.format(save_folder), observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6123512b",
   "metadata": {},
   "source": [
    "#### Run trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cda2dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken by propagate is 0.26097607612609863 seconds\n"
     ]
    }
   ],
   "source": [
    "mc = sim.MCProb(save_folder, n_subdivs, mu_np, sigma, rv0.sample(n_particles).numpy())\n",
    "mc.propagate(n_steps, dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41a9d0e",
   "metadata": {},
   "source": [
    "#### Observe in the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a7ffd7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken by systematic_noisy_resample is 4.7372777462005615 seconds\n"
     ]
    }
   ],
   "source": [
    "X = np.genfromtxt('{}/ensemble.csv'.format(mc.save_folder), delimiter=',').astype(DTYPE)\n",
    "weights = get_weights(observation[0], X)\n",
    "X_r = systematic_noisy_resample(X, weights, 0.5)\n",
    "pd.DataFrame(X_r).to_csv('{}/ensemble.csv'.format(mc.save_folder), index=None, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c830af",
   "metadata": {},
   "source": [
    "#### Do box counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed131123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken by set_grid is 0.32370471954345703 seconds\n",
      "Time taken by assign_pts is 0.3859059810638428 seconds\n",
      "Time taken by compute_p2 is 0.2953987121582031 seconds\n",
      "Time taken by compute_p2 is 0.2882242202758789 seconds\n",
      "Time taken by compute_p2 is 0.286959171295166 seconds\n"
     ]
    }
   ],
   "source": [
    "mc.set_grid(lims=None)\n",
    "mc.assign_pts()\n",
    "p_1f = mc.compute_p2(0, 1, save=False)\n",
    "np.save(save_folder + '/p_1f.npy', p_1f)\n",
    "p_2f = mc.compute_p2(1, 2, save=False)\n",
    "np.save(save_folder + '/p_2f.npy', p_2f)\n",
    "p_3f = mc.compute_p2(2, 0, save=False)\n",
    "np.save(save_folder + '/p_3f.npy', p_3f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3835caa3",
   "metadata": {},
   "source": [
    "#### Save grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddaa1654",
   "metadata": {},
   "outputs": [],
   "source": [
    "low = mc.grid.mins\n",
    "high = mc.grid.maxs\n",
    "x = np.linspace(low[0], high[0], num=n_subdivs+1)[:-1].astype(DTYPE) + mc.grid.h[0]/2. \n",
    "y = np.linspace(low[1], high[1], num=n_subdivs+1)[:-1].astype(DTYPE) + mc.grid.h[1]/2.\n",
    "z = np.linspace(low[2], high[2], num=n_subdivs+1)[:-1].astype(DTYPE) + mc.grid.h[2]/2.\n",
    "np.save('{}/x.npy'.format(save_folder), x)\n",
    "np.save('{}/y.npy'.format(save_folder), y)\n",
    "np.save('{}/z.npy'.format(save_folder), z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d3c2f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.796521"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6606de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
