{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46356898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pinak\\Documents\\GitHub\\fp-solvers\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "from pathlib import Path\n",
    "script_dir = Path(os.path.dirname(os.path.abspath('')))\n",
    "module_dir = str(script_dir)\n",
    "sys.path.insert(0, module_dir + '/modules')\n",
    "print(module_dir)\n",
    "\n",
    "# import the rest of the modules\n",
    "%matplotlib nbagg\n",
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "import matplotlib.pyplot as plt\n",
    "import sim\n",
    "import pandas as pd\n",
    "import tensorflow_probability as tfp\n",
    "import time  \n",
    "import compare\n",
    "tfd = tfp.distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4be9da57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up computation parameters\n",
    "dim = 3\n",
    "n_particles = int(1e6)\n",
    "n_subdivs = 100\n",
    "save_folder = 'L63-pf'\n",
    "n_steps = 3\n",
    "n_repeats = 200\n",
    "dt = 0.01\n",
    "alpha, beta, rho = 10., 8./3., 28.\n",
    "t = dt * n_steps\n",
    "max_comp = int(1e6)\n",
    "quad_method = 'Gauss_Legendre'\n",
    "n_int_subdivs = 100\n",
    "degree = 6\n",
    "DTYPE = 'float32'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8b2832",
   "metadata": {},
   "source": [
    "#### Define $\\mu, \\sigma, p_0, \\sigma_h$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45541914",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mu_np(X):\n",
    "    x, y, z = np.split(X, dim, axis=-1)\n",
    "    p = alpha * (y - x) \n",
    "    q = x * (rho - z) - y \n",
    "    r = x * y - beta * z\n",
    "    return np.concatenate([p, q, r], axis=-1)\n",
    "\n",
    "sigma = 10.\n",
    "sigma_h = 0.1\n",
    "\n",
    "l = np.ones(dim, dtype=DTYPE)\n",
    "g1 = tfd.MultivariateNormalDiag(loc=2.*l, scale_diag=l)\n",
    "g2 = tfd.MultivariateNormalDiag(loc=-2.*l, scale_diag=l)\n",
    "mix = 0.5\n",
    "rv0 = tfd.Mixture(cat=tfd.Categorical(probs=[mix, 1.-mix]), components=[g1, g2])\n",
    "log_p0 = lambda x: tf.reshape(rv0.log_prob(x), (-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57eff847",
   "metadata": {},
   "source": [
    "#### Define observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d32b50d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def H(X):\n",
    "    x, y, z = np.split(X, 3, axis=-1)\n",
    "    return np.concatenate([x, z], axis=-1)\n",
    "\n",
    "def obs(X):\n",
    "    x, y, z = np.split(X, 3, axis=-1)\n",
    "    x = x + np.random.normal(scale=sigma_h, size=x.shape).astype(DTYPE)\n",
    "    z = z + np.random.normal(scale=sigma_h, size=z.shape).astype(DTYPE)\n",
    "    return np.concatenate([x, z], axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26a1a65",
   "metadata": {},
   "source": [
    "#### Set up resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4561621c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights(y, X):\n",
    "    rv1 = tfd.MultivariateNormalDiag(loc=y, scale_diag=sigma_h*np.ones(2).astype(DTYPE))\n",
    "    w = rv1.prob(H(X)).numpy()\n",
    "    return w/w.sum()\n",
    "\n",
    "def systematic_resample(X, weights):\n",
    "        # make N subdivisions, and choose positions with a consistent random offset\n",
    "        positions = (np.random.random() + np.arange(n_particles)) / n_particles\n",
    "        indices = np.zeros(n_particles, 'i')\n",
    "        cumulative_sum = np.cumsum(weights.astype('float64'))\n",
    "        i, j = 0, 0\n",
    "        try:\n",
    "            while i < n_particles:\n",
    "                if positions[i] < cumulative_sum[j]:\n",
    "                    indices[i] = j\n",
    "                    i += 1\n",
    "                else:\n",
    "                    j += 1\n",
    "            particles = np.array([X[i] for i in indices])\n",
    "            return particles\n",
    "        except:\n",
    "            print(i, j)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2a9909",
   "metadata": {},
   "source": [
    "#### Create a true trajectory and observe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6307cf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_state = rv0.sample(1).numpy()\n",
    "for step in range(n_steps):\n",
    "    true_state +=  mu_np(true_state) * dt + sigma * np.random.normal(scale=np.sqrt(dt), size=(1, dim))\n",
    "observation = obs(true_state)\n",
    "np.save('{}/true_state.npy'.format(save_folder), true_state)\n",
    "np.save('{}/observation.npy'.format(save_folder), observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e284443f",
   "metadata": {},
   "source": [
    "#### Run trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cda2dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken by propagate is 2.2906181812286377 seconds\n"
     ]
    }
   ],
   "source": [
    "mc = sim.MCProb(save_folder, n_subdivs, mu_np, sigma, rv0.sample(n_particles).numpy())\n",
    "mc.propagate(n_steps, dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2dbdb4",
   "metadata": {},
   "source": [
    "#### Observe in the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a7ffd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.genfromtxt('{}/ensemble.csv'.format(mc.save_folder), delimiter=',').astype(DTYPE)\n",
    "weights = get_weights(observation[0], X)\n",
    "X_r = systematic_resample(X, weights)\n",
    "pd.DataFrame(X_r).to_csv('{}/ensemble.csv'.format(mc.save_folder), index=None, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d066320",
   "metadata": {},
   "source": [
    "#### Do box counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2f2f6de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken by set_grid is 2.564391851425171 seconds\n",
      "Time taken by assign_pts is 3.230332612991333 seconds\n",
      "Time taken by compute_p2 is 2.858905792236328 seconds\n",
      "Time taken by compute_p2 is 2.838596820831299 seconds\n",
      "Time taken by compute_p2 is 2.9246132373809814 seconds\n"
     ]
    }
   ],
   "source": [
    "mc.set_grid(lims=None)\n",
    "mc.assign_pts()\n",
    "p_1f = mc.compute_p2(0, 1, save=False)\n",
    "np.save(save_folder + '/p_1f.npy', p_1f)\n",
    "p_2f = mc.compute_p2(1, 2, save=False)\n",
    "np.save(save_folder + '/p_2f.npy', p_2f)\n",
    "p_3f = mc.compute_p2(2, 0, save=False)\n",
    "np.save(save_folder + '/p_3f.npy', p_3f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdeba272",
   "metadata": {},
   "source": [
    "#### Save grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "901f273c",
   "metadata": {},
   "outputs": [],
   "source": [
    "low = mc.grid.mins\n",
    "high = mc.grid.maxs\n",
    "x = np.linspace(low[0], high[0], num=n_subdivs+1)[:-1].astype(DTYPE) + mc.grid.h[0]/2. \n",
    "y = np.linspace(low[1], high[1], num=n_subdivs+1)[:-1].astype(DTYPE) + mc.grid.h[1]/2.\n",
    "z = np.linspace(low[2], high[2], num=n_subdivs+1)[:-1].astype(DTYPE) + mc.grid.h[2]/2.\n",
    "np.save('{}/x.npy'.format(save_folder), x)\n",
    "np.save('{}/y.npy'.format(save_folder), y)\n",
    "np.save('{}/z.npy'.format(save_folder), z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35294b90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.0745685,  4.412161 ,  0.7173615],\n",
       "       [-1.0268593, -2.1504521, -3.3444583],\n",
       "       [ 1.7180123,  5.113201 , -0.7932818],\n",
       "       ...,\n",
       "       [ 2.1291478,  1.601912 ,  3.533174 ],\n",
       "       [ 0.8721781, -3.2017198, -1.9234207],\n",
       "       [-3.709998 , -5.120886 , -3.836434 ]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_r - X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e3ac93",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffa35e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
